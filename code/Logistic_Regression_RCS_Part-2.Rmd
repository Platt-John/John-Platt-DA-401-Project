---
title: "Logistic Regression and RCS Analysis Part 2"
author: "John Platt"
date: "2025-10-18"
output: 
  html_document:
    code_folding: hide
---

## Introduction

Ensuring assumptions are met beforehand and validating model fit, we conduct survey-weighted, standardized logistic regression to examine the association between marijuana use and suicidal ideation. An unadjusted model without confounders will be conducted first, and subsequently, a fully adjusted model will be done.

## Meeting Logistic Regression Assumptions

First, we get our dataset ready and check assumptions before performing standardized logistic regression.

```{r loading in and modifying original dataset, include=TRUE, message=FALSE, warning=FALSE}
#File -> New Project -> Set existing GitHub Repository as working directory with data2 as a subfolder outside the repository and the NSDUH_2023.Rdata file in the subfolder
#File -> New Project -> Set existing GitHub Repository as working directory with data2 as a subfolder outside the repository and the NSDUH_2023.Rdata file in the subfolder
#Load in the data
load("C:/Users/John Platt/OneDrive/data2/NSDUH_2021_2023.Rdata")
#Required packages:
#dplyr
library(dplyr) #data wrangling and manipulation
#Select a subset of the 2021-2023 NSDUH data that has the 27 necessary columns
data<-data %>% select(ANALWT2_C3,YEAR,VESTR_C,VEREP,IRSEX,CATAGE,NEWRACE2,EDUHIGHCAT,IRWRKSTAT18,IRHHSIZ2,IRPRVHLT,INCOME,IRALCFY,IRMJFY,IRCOCFY,IRCIGFM,IRNICVAP30N,IRHALLUCYFQ,IRALCBNG30D,SUTINPPY,IRDSTNRV12,IRDSTEFF12,IRIMPCONCN,IRSUICTHNK,IRAMDEYR,MHTINPPY,AMISUD5ANYO)
#Replace missing values with 0 for substance use variables
zero_codes <- list(
  IRALCFY      = c(991, 993),
  IRCIGFM      = c(91, 93),
  IRMJFY       = c(991, 993),
  IRCOCFY      = c(991, 993),
  IRHALLUCYFQ  = c(991, 993),
  IRNICVAP30N  = c(91, 93),  # 91/93 here mean no use as well
  IRALCBNG30D  = c(91, 93)
)

for (v in names(zero_codes)) {
  data[[v]][data[[v]] %in% zero_codes[[v]]] <- 0
}
# Replace -9 (missing) with NA for these three variables only
vars_with_neg9 <- c("IRNICVAP30N", "SUTINPPY", "MHTINPPY")

for (v in vars_with_neg9) {
  if (v %in% names(data)) {
    data[[v]][data[[v]] == -9] <- NA
  }}
#Decoding of IRSEX column
data$IRSEX<-factor(data$IRSEX, 
                    levels=c(1,2),labels=c('Male',"Female"))
#Decoding of EDUHIGHCAT column
data$EDUHIGHCAT<-factor(data$EDUHIGHCAT, 
                    levels=c(1,2,3,4,5),
                    labels=c("Less high school","High school grad","Some coll/Assoc Dg","College graduate","12 to 17 year olds"))
#Decoding of IRPRVHLT column
data$IRPRVHLT<-factor(data$IRPRVHLT, 
                    levels=c(1,2),
                    labels=c("Yes","No"))
#Decoding of IRHHSIZ2 column
data$IRHHSIZ2<-factor(data$IRHHSIZ2, 
                    levels=c(1,2,3,4,5,6),
                    labels=c("One person in household","Two people in household","Three people in household","Four people in household","Five people in household","6 or more people in household"))
#Decoding of INCOME column
data$INCOME<-factor(data$INCOME,
                    levels=c(1,2,3,4),
                    labels=c("Less than $20,000","$20,000-$49,999","$50,000-$74,999","$75,000 or More"))
#Decoding of SUTINPPY column
data$SUTINPPY<-factor(data$SUTINPPY, 
                    levels=c(0,1),
                    labels=c("No","Yes"))
#Decoding of IRDSTNRV12 column
data$IRDSTNRV12<-factor(data$IRDSTNRV12, 
                    levels=c(1,2,3,4,5),
                    labels=c("All of the time","Most of the time","Some of the time","A little of the time","None of the time"))
#Decoding of IRDSTEFF12 column
data$IRDSTEFF12<-factor(data$IRDSTEFF12,
                        levels=c(1,2,3,4,5),
                        labels=c("All of the time","Most of the time","Some of the time","A little of the time","None of the time"))
#Decoding of IRIMPCONCN column
data$IRIMPCONCN<-factor(data$IRIMPCONCN,
                        levels=c(1,2,3,4),
                        labels=c("No difficulty","Mild difficultly","Moderate difficulty","Severe difficulty"))
#Decoding of IRSUICTHNK column
data$IRSUICTHNK<-factor(data$IRSUICTHNK,
                        levels=c(0,1),
                        labels=c("No","Yes"))
#Decoding of IRAMDEYR column
data$IRAMDEYR<-factor(data$IRAMDEYR,
                        levels=c(0,1),
                        labels=c("No","Yes"))
#Decoding of MHTINPPY column
data$MHTINPPY<-factor(data$MHTINPPY,
                        levels=c(0,1),
                        labels=c("No","Yes"))
#Decoding of AMISUD5ANYO column
#Note: missing values will be filtered out when examine the population subset: young adults
data$AMISUD5ANYO<-factor(data$AMISUD5ANYO,
                        levels=c(1,2,3,4),
                        labels=c("SUD only, no AMI","AMI only, no SUD","SUD and AMI","Neither SUD or AMI"))
#Code suicidal ideation variable as numeric
data$IRSUICTHNK <- ifelse(data$IRSUICTHNK == "Yes", 1, ifelse(data$IRSUICTHNK == "No", 0, NA))
#Check data type of dataframe columns
str(data)
```

```{r dummy variables}
#Required packages:
#fastDummies
library(fastDummies) #Dummy variable creation
#Convert nominal variables into dummy variables and drop reference dummy to avoid "dummy variable trap"
data <- dummy_cols(data, select_columns = c("NEWRACE2","IRWRKSTAT18"), remove_first_dummy = TRUE, remove_selected_columns = TRUE)
head(data)
```

```{r creating standardized columns from continuous substance use variables}
#Create standardized marijuana use column, subtracting the mean and dividing by standard deviation->Result: New variable with mean equal to 0 and standard deviation equal to 1
data$IRMJFY_std     <- scale(data$IRMJFY, center = TRUE, scale = TRUE)
#Create standardized cocaine use column, subtracting the mean and dividing by standard deviation->Result: New variable with mean equal to 0 and standard deviation equal to 1
data$IRCOCFY_std  <- scale(data$IRCOCFY, center = TRUE, scale = TRUE)
#Create standardized hallucinogen use column, subtracting the mean and dividing by standard deviation->Result: New variable with mean equal to 0 and standard deviation equal to 1
data$IRHALLUCYFQ_std    <- scale(data$IRHALLUCYFQ, center = TRUE, scale = TRUE)
```

```{r specify survey design and check sample size as well as strata and PSUs}
#Install survey package
library(survey) #Library for survey design
options(survey.lonely.psu = "adjust")  #common & documented choice to adjust variance if there are single psus within stratum
#Specify survey design
des <- svydesign(
  id      = ~VEREP, #PSU/cluster id
  strata  = ~VESTR_C, #variance strata
  weights = ~ANALWT2_C3, #analysis weight
  data    = data, #2021-2023 NSDUH dataframe
  nest = TRUE
)
#Check strata, PSUs, and effective sample size
young_adults <- subset(des, CATAGE == 2)  #CATAGE==2 for 18–25
#Number of unique strata and PSUs in the subpopulation
length(unique(young_adults$variables$VESTR_C))
length(unique(young_adults$variables$VEREP))
#Compute effective sample size
w <- weights(young_adults)
ess <- (sum(w)^2) / sum(w^2)
ess
```

```{r Check for multicollinearity}
#File -> New Project -> Set existing GitHub Repository as working directory with data2 as a subfolder outside the repository and the NSDUH_2023.Rdata file in the subfolder
#Load in the data
load("C:/Users/John Platt/OneDrive/data2/NSDUH_2021_2023.Rdata")
#Required packages:
#dplyr
library(dplyr) #data wrangling and manipulation
#Select a subset of the 2021-2023 NSDUH data that has the 27 necessary columns
data<-data %>% select(ANALWT2_C3,YEAR,VESTR_C,VEREP,IRSEX,CATAGE,NEWRACE2,EDUHIGHCAT,IRWRKSTAT18,IRHHSIZ2,IRPRVHLT,INCOME,IRALCFY,IRMJFY,IRCOCFY,IRCIGFM,IRNICVAP30N,IRHALLUCYFQ,IRALCBNG30D,SUTINPPY,IRDSTNRV12,IRDSTEFF12,IRIMPCONCN,IRSUICTHNK,IRAMDEYR,MHTINPPY,AMISUD5ANYO)
data
#Replace missing values with 0 for substance use variables
zero_codes <- list(
  IRALCFY      = c(991, 993),
  IRCIGFM      = c(91, 93),
  IRMJFY       = c(991, 993),
  IRCOCFY      = c(991, 993),
  IRHALLUCYFQ  = c(991, 993),
  IRNICVAP30N  = c(91, 93),  # 91/93 here mean no use as well
  IRALCBNG30D  = c(91, 93)
)

for (v in names(zero_codes)) {
  data[[v]][data[[v]] %in% zero_codes[[v]]] <- 0
}
# Replace -9 (missing) with NA for these three variables only
vars_with_neg9 <- c("IRNICVAP30N", "SUTINPPY", "MHTINPPY")

for (v in vars_with_neg9) {
  if (v %in% names(data)) {
    data[[v]][data[[v]] == -9] <- NA
  }}
#Required packages:
#fastDummies
library(fastDummies) #Dummy variable creation
#Convert nominal variables into dummy variables and drop reference dummy to avoid "dummy variable trap"
data <- dummy_cols(data, select_columns = c("NEWRACE2","IRWRKSTAT18"), remove_first_dummy = TRUE, remove_selected_columns = TRUE)
head(data)
#Create standardized marijuana use column, subtracting the mean and dividing by standard deviation->Result: New variable with mean equal to 0 and standard deviation equal to 1
data$IRMJFY_std     <- scale(data$IRMJFY, center = TRUE, scale = TRUE)
#Create standardized cocaine use column, subtracting the mean and dividing by standard deviation->Result: New variable with mean equal to 0 and standard deviation equal to 1
data$IRCOCFY_std  <- scale(data$IRCOCFY, center = TRUE, scale = TRUE)
#Create standardized hallucinogen use column, subtracting the mean and dividing by standard deviation->Result: New variable with mean equal to 0 and standard deviation equal to 1
data$IRHALLUCYFQ_std    <- scale(data$IRHALLUCYFQ, center = TRUE, scale = TRUE)
#Install survey package
library(survey) #Library for survey design
options(survey.lonely.psu = "adjust")  #common & documented choice to adjust variance if there are single psus within stratum
#Specify survey design
des2 <- svydesign(
  id      = ~VEREP, #PSU/cluster id
  strata  = ~VESTR_C, #variance strata
  weights = ~ANALWT2_C3, #analysis weight
  data    = data, #2021-2023 NSDUH dataframe
  nest = TRUE
)
#Filter to subpop
young_adults2 <- subset(des2, CATAGE == 2)  #CATAGE==2 for 18–25
#Variables to include in the correlation matrix
vars <- c("IRMJFY_std","IRCOCFY_std","IRHALLUCYFQ_std","IRSEX","EDUHIGHCAT","IRPRVHLT","IRHHSIZ2","IRALCFY","IRNICVAP30N","IRALCBNG30D","SUTINPPY","IRDSTNRV12","IRIMPCONCN","NEWRACE2_2","NEWRACE2_3","NEWRACE2_4","NEWRACE2_5","NEWRACE2_6",
"NEWRACE2_7","IRWRKSTAT18_2","IRWRKSTAT18_3","IRWRKSTAT18_4")
#Define a function to compute a survey-weighted correlation matrix
survey_cor_matrix <- function(design, vars) {
  p <- length(vars)                                # Count how many variables we're including
  cor_mat <- matrix(NA_real_, p, p,                # Pre-allocate an empty p x p matrix of NA (numeric)
                    dimnames = list(vars, vars))   # Name the rows and columns with the variable names
  
  diag(cor_mat) <- 1                               # Set the diagonal (correlation of a variable with itself) to 1
  
  # If fewer than 2 variables remain, return the diagonal-only matrix (no correlations possible)
  if (p < 2) return(cor_mat)

  # Outer loop: iterate over each variable i (rows)
  for (i in 1:(p-1)) {
    # Inner loop: iterate over variables j (columns), but only for upper triangle (j > i)
    for (j in (i+1):p) {

      # Try to compute the 2x2 survey-weighted covariance matrix for variables i and j
      # - Uses svyvar() which accounts for weights, strata, and PSUs
      # - na.rm = TRUE removes missing data
      # - try(...) ensures the loop continues even if svyvar() fails for some pair
      cov_mat <- try(
        survey::svyvar(
          as.formula(paste("~", vars[i], "+", vars[j])), # dynamically builds a formula like ~VAR1 + VAR2
          design = design,                              # use the design object (already subset to CATAGE == 2)
          na.rm  = TRUE                                 # remove missing values before computing covariance
        ),
        silent = TRUE                                   # don't print errors, just skip failed pairs
      )

      # If svyvar() failed or returned something other than a 2x2 covariance matrix, skip this pair
      if (inherits(cov_mat, "try-error") || !is.matrix(cov_mat) || any(dim(cov_mat) != 2)) next

      # Extract covariance and variances from the 2x2 matrix
      cov_val <- cov_mat[1, 2]                          # Covariance between variable i and variable j
      var_i   <- cov_mat[1, 1]                          # Variance of variable i
      var_j   <- cov_mat[2, 2]                          # Variance of variable j

      # If any values are NA or variance is zero/negative, skip this pair
      if (is.na(cov_val) || is.na(var_i) || is.na(var_j) || var_i <= 0 || var_j <= 0) next

      # Calculate the Pearson correlation:
      #    r = cov(X, Y) / (sqrt(var(X)) * sqrt(var(Y)))
      # This is the standard formula but using design-adjusted covariances and variances.
      r <- cov_val / sqrt(var_i * var_j)

      # Fill the correlation matrix symmetrically
      cor_mat[i, j] <- r                               # Upper triangle (row i, column j)
      cor_mat[j, i] <- r                               # Lower triangle (row j, column i)
    }
  }
  # Return the completed survey-weighted correlation matrix
  cor_mat
}

#Run the function to calculate the survey-weighted correlation matrix
cor_matrix <- survey_cor_matrix(young_adults2, vars)
#Display the correlation matrix, rounding all values to 3 decimal places for readability
round(cor_matrix, 3)
```

```{r calculate VIFs}
# Load the 'car' package to access the vif() function for multicollinearity checks
library(car)

# Extract the domain-restricted data frame (all variables available in the design)
d  <- young_adults2$variables

# Extract the final analysis weights as a numeric vector aligned with 'd'
w  <- as.numeric(weights(young_adults2))

# Define the predictor set you plan to screen for multicollinearity
preds <- c("IRMJFY_std","IRCOCFY_std","IRHALLUCYFQ_std","IRSEX","EDUHIGHCAT","IRPRVHLT","IRHHSIZ2","INCOME","IRALCFY","IRCIGFM","IRNICVAP30N","IRALCBNG30D","SUTINPPY","IRDSTNRV12","IRIMPCONCN","NEWRACE2_2","NEWRACE2_3","NEWRACE2_4","NEWRACE2_5","NEWRACE2_6",
"NEWRACE2_7","IRWRKSTAT18_2","IRWRKSTAT18_3","IRWRKSTAT18_4")

# Build a predictors-only data frame using the selected columns
X  <- d[preds]

# Identify rows with complete data across ALL predictors and the weight vector
ok <- complete.cases(X, w)

# Keep only complete rows in the predictor matrix (ensures X and weights have matching length)
X  <- X[ok, , drop = FALSE]

# Keep the corresponding weights for those complete rows
w2 <- w[ok]

# Helper function: returns TRUE if a column is constant (all same value or all NA after omitting NAs)
is_constant <- function(x) length(unique(na.omit(x))) <= 1

# Find columns that are constant/degenerate after the domain + NA filtering
const_cols  <- names(X)[vapply(X, is_constant, logical(1))]

# Drop constant columns (they cause singularities and NaN VIFs)
if (length(const_cols)) {
  message("Dropping constant columns: ", paste(const_cols, collapse = ", "))
  X <- X[ , setdiff(names(X), const_cols), drop = FALSE]
}

# Set a seed so the random dummy response below is reproducible
set.seed(1)

# Create a NON-constant dummy response for lm(); VIFs depend only on X, but lm() needs a y with variance
z <- rnorm(nrow(X))

# Fit a temporary weighted linear model to let lm() detect aliased (perfectly collinear) predictors
tmp_fit   <- lm(z ~ ., data = X, weights = w2)

# Get the coefficient names that survived in the model (includes "(Intercept)")
keep      <- setdiff(names(coef(tmp_fit)), "(Intercept)")

# Anything present in X but not in 'keep' was dropped as aliased; mark for removal
drop_cols <- setdiff(names(X), keep)

# If aliased predictors exist, drop them and keep only the non-aliased set
if (length(drop_cols)) {
  message("Dropping aliased columns: ", paste(drop_cols, collapse = ", "))
  X <- X[ , keep, drop = FALSE]
}

#Refit a clean weighted linear model using only non-aliased, non-constant predictors
fit_wls <- lm(z ~ ., data = X, weights = w2)

#Compute Variance Inflation Factors for each remaining predictor
vifs    <- vif(fit_wls)

#Sort VIFs from highest to lowest (helps you quickly spot the worst offenders)
sort(vifs, decreasing = TRUE)
```
# Standardized Logistic Regression

```{r unadjusted pseudo maximum likelihood logistic regression}
#Unadjusted logistic regression model between illicit substance use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRMJFY_std, design = young_adults, family = quasibinomial())

# Coefficients → ORs with 95% CIs
co <- coef(fit)
vc <- vcov(fit)
se <- sqrt(diag(vc))
z  <- qnorm(0.975)

est <- data.frame(
  term = names(co),
  beta = co,
  se   = se,
  OR   = exp(co),
  LCL  = exp(co - z*se),
  UCL  = exp(co + z*se),
  p    = 2*pnorm(-abs(co/se))
)

# Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r plot residuals vs fitted values for unadjusted PML model 1}
res_dev <- residuals(fit, type = "deviance")
plot(fitted(fit), res_dev, xlab="Fitted (p-hat)", ylab="Deviance residuals",
     main="Residuals vs Fitted (Deviance)", pch=19, col="steelblue")
abline(h=0, lty=2, col="red")
```

```{r unadjusted pseudo maximum likelihood logistic regression 1}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRSEX, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 2}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ EDUHIGHCAT, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 3}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRPRVHLT, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 4}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRHHSIZ2, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 5}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ INCOME, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 6}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRALCFY, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 7}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRCIGFM, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 8}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRNICVAP30N, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 9}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRALCBNG30D, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 10}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ SUTINPPY, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 11}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRDSTNRV12, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 12}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRIMPCONCN, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 13}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r unadjusted pseudo maximum likelihood logistic regression 14}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4, design = young_adults, family = quasibinomial())
#Coefficients → ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r non-linear test 1, warning=FALSE, message=FALSE}
#Required libraries: rms 
library(rms)
#Fit linear model
fit_linear <- svyglm(
  IRSUICTHNK ~ IRMJFY_std,
  design = young_adults,
  family = quasibinomial()
)
#Fit non-linear model
fit_rcs <- svyglm(
  IRSUICTHNK ~ rcs(IRMJFY_std),
  design = young_adults,
  family = quasibinomial()
)
#Test the null hypothesis: nonlinear spline components = 0
regTermTest(fit_rcs, ~ rcs(IRMJFY_std))
```

```{r plot residuals vs fitted values for RCS unadjusted PML model}
res_dev <- residuals(fit_rcs, type = "deviance")
plot(fitted(fit_rcs), res_dev, xlab="Fitted (predicted values)", ylab="Deviance residuals",
     main="Residuals vs Fitted (Deviance)", pch=19, col="steelblue")
abline(h=0, lty=2, col="red")
```

```{r adjusted pseudo maximum likelihood logistic regression}
#Fit the adjusted PML logistic regression (quasibinomial for robust SEs)
fit <- svyglm(
  IRSUICTHNK ~ IRMJFY_std + IRSEX + EDUHIGHCAT + IRPRVHLT + IRHHSIZ2 + IRALCFY + IRNICVAP30N + IRALCBNG30D + SUTINPPY +
               IRDSTNRV12 + IRIMPCONCN +
               NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
               IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = young_adults,
  family = quasibinomial()
)
#Coefficients → ORs with 95% CIs
co <- coef(fit)
vc <- vcov(fit)
se <- sqrt(diag(vc))
z  <- qnorm(0.975)
#Create dataframe with estimates
est <- data.frame(
  term = names(co),
  beta = co,
  se   = se,
  OR   = exp(co),
  LCL  = exp(co - z*se),
  UCL  = exp(co + z*se),
  p    = 2*pnorm(-abs(co/se))
)

#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

Now we add interactions into our logistic regression model. Since we don't have sufficient time to test all interactions, we will go ahead and test the interactions we added to our first model (both interactions turned out to be not statistically significant).

```{r adjusted pseudo maximum likelihood logistic regression with interactions}
#Fit the adjusted PML logistic regression (quasibinomial for robust SEs)
fit <- svyglm(
  IRSUICTHNK ~ IRMJFY_std + IRSEX + EDUHIGHCAT + IRPRVHLT + IRHHSIZ2 +
               IRALCFY + IRNICVAP30N + IRALCBNG30D + SUTINPPY +
               IRDSTNRV12 + IRIMPCONCN +
               NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
               IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = young_adults,
  family = quasibinomial()
)
#Coefficients → ORs with 95% CIs
co <- coef(fit)
vc <- vcov(fit)
se <- sqrt(diag(vc))
z  <- qnorm(0.975)
#Data frame with estimates
est <- data.frame(
  term = names(co),
  beta = co,
  se   = se,
  OR   = exp(co),
  LCL  = exp(co - z*se),
  UCL  = exp(co + z*se),
  p    = 2*pnorm(-abs(co/se))
)

#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
#Do design-adjusted wald test for interaction (p-value <.05 means the relationship between cannabis use and suicidal ideation significantly differs by the interaction term and coefficient for the interaction term is not equal to 0)
#regTermTest(fit_int, ~ IRMJFY_std:NEWRACE2_3)
```

```{r plot residuals vs fitted values for adjusted PML model}
res_dev <- residuals(fit, type = "deviance")
plot(fitted(fit), res_dev, xlab="Fitted (p-hat)", ylab="Deviance residuals",
     main="Residuals vs Fitted (Deviance)", pch=19, col="steelblue")
abline(h=0, lty=2, col="red")
```

```{r non-linear test, warning=FALSE, message=FALSE}
#Required libraries: rms 
library(rms)
#Fit linear model
fit_linear <- svyglm(
  IRSUICTHNK ~ IRMJFY_std + IRSEX + EDUHIGHCAT + IRPRVHLT + IRHHSIZ2 +
               IRALCFY + IRNICVAP30N + IRALCBNG30D + SUTINPPY +
               IRDSTNRV12 + IRIMPCONCN +
               NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
               IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = young_adults,
  family = quasibinomial()
)
#Fit non-linear model
fit_rcs <- svyglm(
  IRSUICTHNK ~ rcs(IRMJFY_std) +
 IRSEX + EDUHIGHCAT + IRPRVHLT + IRHHSIZ2 +
    IRALCFY + IRNICVAP30N + IRALCBNG30D + SUTINPPY +
    IRDSTNRV12 + IRIMPCONCN +
    NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
    IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = young_adults,
  family = quasibinomial()
)
#Test the null hypothesis: nonlinear spline components = 0
regTermTest(fit_rcs, ~ rcs(IRMJFY_std))
```

```{r plot residuals vs fitted values for RCS adjusted PML model}
res_dev <- residuals(fit_rcs, type = "deviance")
plot(fitted(fit_rcs), res_dev, xlab="Fitted (p-hat)", ylab="Deviance residuals",
     main="Residuals vs Fitted (Deviance)", pch=19, col="steelblue")
abline(h=0, lty=2, col="red")
```

