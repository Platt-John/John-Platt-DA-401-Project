---
title: "Logistic Regression and RCS Analysis Part 1"
author: "John Platt"
date: "2025-10-14"
output: 
  html_document:
    code_folding: hide
---

## Introduction

Ensuring assumptions are met beforehand and validating model fit, we conduct survey-weighted logistic regression to examine the association between our main illicit substance use predictors (marijuana use, cocaine use, hallucinogen use) and suicidal ideation. An unadjusted model without confounders will be conducted first, and subsequently, a fully adjusted model will be done.

## Meeting Logistic Regression Assumptions

First, we get our dataset ready and check assumptions before performing logistic regression.

```{r loading in and modifying original dataset, include=TRUE, message=FALSE, warning=FALSE}
#File -> New Project -> Set existing GitHub Repository as working directory with data2 as a subfolder outside the repository and the NSDUH_2023.Rdata file in the subfolder
#Load in the data
load("C:/Users/John Platt/OneDrive/data2/NSDUH_2021_2023.Rdata")
#Required packages:
#dplyr
library(dplyr) #data wrangling and manipulation
#Select a subset of the 2021-2023 NSDUH data that has the 27 necessary columns
data<-data %>% select(ANALWT2_C3,YEAR,VESTR_C,VEREP,IRSEX,CATAGE,NEWRACE2,EDUHIGHCAT,IRWRKSTAT18,IRHHSIZ2,IRPRVHLT,INCOME,IRALCFY,IRMJFY,IRCOCFY,IRCIGFM,IRNICVAP30N,IRHALLUCYFQ,IRALCBNG30D,SUTINPPY,IRDSTNRV12,IRDSTEFF12,IRIMPCONCN,IRSUICTHNK,IRAMDEYR,MHTINPPY,AMISUD5ANYO)
data
# Replace all 91s with 0 in the entire data frame
data[data == 91] <- 0
# Replace all 93s with 0 in the entire data frame
data[data == 93] <- 0
# Replace all 991s with 0 in the entire data frame
data[data == 991] <- 0
# Replace all 993s with 0 in the entire data frame
data[data == 993] <- 0
```

```{r dummy variables and illicit substance use conversion}
#Required packages:
#fastDummies
library(fastDummies) #Dummy variable creation
#Convert nominal variables into dummy variables and drop reference dummy to avoid "dummy variable trap"
data <- dummy_cols(data, select_columns = c("NEWRACE2","IRWRKSTAT18"), remove_first_dummy = TRUE, remove_selected_columns = TRUE)
head(data)
#Convert illicit substance use variables into categories
data$IRMJFY2 <- cut(data$IRMJFY,
                    breaks = 4,   # number of categories
                    labels = c("0-90", "90-180", "180-270", "270-360"),
                    include.lowest = TRUE)
data$IRCOCFY2 <- cut(data$IRCOCFY,
                    breaks = 4,   # number of categories
                    labels = c("0-90", "90-180", "180-270", "270-360"),
                    include.lowest = TRUE)
data$IRHALLUCYFQ2 <- cut(data$IRHALLUCYFQ,
                    breaks = 4,   # number of categories
                    labels = c("0-90", "90-180", "180-270", "270-360"),
                    include.lowest = TRUE)
#Convert categories to numerical codes
data$IRMJFY2 <- ifelse(data$IRMJFY2=="0-90",1,ifelse(data$IRMJFY2=="90-180",2,ifelse(data$IRMJFY2=="180-270",3,ifelse(data$IRMJFY=="270-360",4,NA))))
data$IRCOCFY2 <- ifelse(data$IRCOCFY2=="0-90",1,ifelse(data$IRCOCFY2=="90-180",2,ifelse(data$IRCOCFY2=="180-270",3,ifelse(data$IRCOCFY2=="270-360",4,NA))))
data$IRHALLUCYFQ2 <- ifelse(data$IRHALLUCYFQ2=="0-90",1,ifelse(data$IRHALLUCYFQ2=="90-180",2,ifelse(data$IRHALLUCYFQ2=="180-270",3,ifelse(data$IRHALLUCYFQ2=="270-360",4,NA))))
```

```{r specify survey design and check sample size as well as strata and PSUs}
#Install survey package
library(survey) #Library for survey design
options(survey.lonely.psu = "adjust")  #common & documented choice to adjust variance if there are single psus within stratum
#Specify survey design
des <- svydesign(
  id      = ~VEREP, #PSU/cluster id
  strata  = ~VESTR_C, #variance strata
  weights = ~ANALWT2_C3, #analysis weight
  data    = data, #2021-2023 NSDUH dataframe
  nest = TRUE
)
#Check strata, PSUs, and effective sample size for young adults
young_adults <- subset(des, CATAGE == 2)  #CATAGE==2 for 18â€“25
#Number of unique strata and PSUs in the subpopulation
length(unique(young_adults$variables$VESTR_C))
length(unique(young_adults$variables$VEREP))
#Compute effective sample size
w <- weights(young_adults)
ess <- (sum(w)^2) / sum(w^2)
ess
```

```{r Check for multicollinearity}
#Variables to include in the correlation matrix
vars <- c("IRSEX","EDUHIGHCAT","IRPRVHLT","IRHHSIZ2","INCOME","IRALCFY","IRCIGFM","IRNICVAP30N","IRALCBNG30D","SUTINPPY","IRDSTNRV12","IRIMPCONCN","IRMJFY2","NEWRACE2_2","NEWRACE2_3","NEWRACE2_4","NEWRACE2_5","NEWRACE2_6",
"NEWRACE2_7","IRWRKSTAT18_2","IRWRKSTAT18_3","IRWRKSTAT18_4")
#Restrict survey design to subpopulation of interest: young adults
des_dom <- subset(des, CATAGE == 2)
#Define a function to compute a survey-weighted correlation matrix
survey_cor_matrix <- function(design, vars) {
  p <- length(vars) #Count how many variables we're including
  cor_mat <- matrix(NA_real_, p, p, #Pre-allocate an empty p x p matrix of NA (numeric)
        dimnames = list(vars, vars)) #Name the rows and columns with the variable names
  diag(cor_mat) <- 1 #Set the diagonal (correlation of a variable with itself) to 1
  #Outer loop: iterate over each variable i (rows)
  for (i in 1:(p-1)) {
    #Inner loop: iterate over variables j (columns), but only for upper triangle (j > i)
    for (j in (i+1):p) {
      #Try to compute the 2x2 survey-weighted covariance matrix for variables i and j
      #Uses svyvar() which accounts for weights, strata, and PSUs
      #na.rm = TRUE removes missing data
      #Try(...) ensures the loop continues even if svyvar() fails for some pair
      cov_mat <- try(
        svyvar(
          as.formula(paste("~", vars[i], "+", vars[j])), #Dynamically builds a formula like ~VAR1 + VAR2
          design = design, #Use the design object (already subset to CATAGE == 2)
          na.rm  = TRUE #Remove missing values before computing covariance
        ),
        silent = TRUE #Don't print errors, just skip failed pairs
      )
      #Extract covariance and variances from the 2x2 matrix
      cov_val <- cov_mat[1, 2] #Covariance between variable i and variable j
      var_i   <- cov_mat[1, 1] #Variance of variable i
      var_j   <- cov_mat[2, 2] #Variance of variable j

      #If any values are NA or variance is zero/negative, skip this pair
      if (is.na(cov_val) || is.na(var_i) || is.na(var_j) || var_i <= 0 || var_j <= 0) next

      #Calculate the Pearson correlation:
      #r = cov(X, Y) / (sqrt(var(X)) * sqrt(var(Y)))
      #This is the standard formula but using design-adjusted covariances and variances.
      r <- cov_val / sqrt(var_i * var_j)

      #Fill the correlation matrix symmetrically
      cor_mat[i, j] <- r #Upper triangle (row i, column j)
      cor_mat[j, i] <- r #Lower triangle (row j, column i)
    }
  }
  #Return the completed survey-weighted correlation matrix
  cor_mat
}

#Run the function to calculate the survey-weighted correlation matrix
#    - des_dom is your survey design restricted to CATAGE == 2
#    - vars is the list of usable variables
cor_matrix <- survey_cor_matrix(des_dom, vars)

#Display the correlation matrix, rounding all values to 3 decimal places for readability
round(cor_matrix, 3)
```

```{r calculate VIFs}
#Load the 'car' package to access the vif() function for multicollinearity checks
library(car)
#Create a domain-restricted survey design (keeps weights/PSUs/strata intact, but restricts to CATAGE == 2)
des_dom <- subset(des, CATAGE == 2)
#Extract the domain-restricted data frame (all variables available in the design)
d  <- des_dom$variables
#Extract the final analysis weights as a numeric vector aligned with 'd'
w  <- as.numeric(weights(des_dom))
# Define the predictor set you plan to screen for multicollinearity
preds <- c("IRSEX","EDUHIGHCAT","IRPRVHLT","IRHHSIZ2","INCOME","IRALCFY","IRCIGFM",
           "IRNICVAP30N","IRALCBNG30D","SUTINPPY","IRDSTNRV12","IRIMPCONCN",
           "IRMJFY2","NEWRACE2_2","NEWRACE2_3","NEWRACE2_4","NEWRACE2_5","NEWRACE2_6",
           "NEWRACE2_7","IRWRKSTAT18_2","IRWRKSTAT18_3","IRWRKSTAT18_4")
#Build a predictors-only data frame using the selected columns
X  <- d[preds]
#Identify rows with complete data across ALL predictors and the weight vector
ok <- complete.cases(X, w)
#Keep only complete rows in the predictor matrix (ensures X and weights have matching length)
X  <- X[ok, , drop = FALSE]
#Keep the corresponding weights for those complete rows
w2 <- w[ok]
#Helper function: returns TRUE if a column is constant (all same value or all NA after omitting NAs)
is_constant <- function(x) length(unique(na.omit(x))) <= 1
#Find columns that are constant/degenerate after the domain + NA filtering
const_cols  <- names(X)[vapply(X, is_constant, logical(1))]
#Drop constant columns (they cause singularities and NaN VIFs)
if (length(const_cols)) {
  message("Dropping constant columns: ", paste(const_cols, collapse = ", "))
  X <- X[ , setdiff(names(X), const_cols), drop = FALSE]
}
#Set a seed so the random dummy response below is reproducible
set.seed(1)
#Create a NON-constant dummy response for lm(); VIFs depend only on X, but lm() needs a y with variance
z <- rnorm(nrow(X))
#Fit a temporary weighted linear model to let lm() detect aliased (perfectly collinear) predictors
tmp_fit   <- lm(z ~ ., data = X, weights = w2)
#Get the coefficient names that survived in the model (includes "(Intercept)")
keep      <- setdiff(names(coef(tmp_fit)), "(Intercept)")
#Anything present in X but not in 'keep' was dropped as aliased; mark for removal
drop_cols <- setdiff(names(X), keep)
#If aliased predictors exist, drop them and keep only the non-aliased set
if (length(drop_cols)) {
  message("Dropping aliased columns: ", paste(drop_cols, collapse = ", "))
  X <- X[ , keep, drop = FALSE]
}
#Refit a clean weighted linear model using only non-aliased, non-constant predictors
fit_wls <- lm(z ~ ., data = X, weights = w2)
#Compute Variance Inflation Factors for each remaining predictor
vifs    <- vif(fit_wls)
#Sort VIFs from highest to lowest (helps you quickly spot the worst offenders)
sort(vifs, decreasing = TRUE)
```

# Logistic Regression

Now we code our unadjusted and adjusted logistic regression models. 

```{r unadjusted pseudo maximum likelihood logistic regression}
#Fit unadjusted logistic regression model between marijuana use and suicidal ideation
fit <- svyglm(IRSUICTHNK ~ IRMJFY2, design = des_dom, family = quasibinomial())
#Coefficients â†’ ORs with 95% CIs
co <- coef(fit) #Beta coefficients
vc <- vcov(fit) #Variance-covariance matrix
se <- sqrt(diag(vc)) #Standard error
z  <- qnorm(0.975) #Z-score for 95% confidence interval
#Create dataframe with estimates
est <- data.frame(
  term = names(co), #Model variables
  beta = co, #Beta coefficient
  se   = se, #Standard eror
  OR   = exp(co), #Odds ratio
  LCL  = exp(co - z*se), #Odds ratio lower confidence level
  UCL  = exp(co + z*se), #Odds ratio upper confidence level
  p    = 2*pnorm(-abs(co/se)) #P-value for odds ratio
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

```{r plot residuals vs fitted values for unadjusted PML model}
#Get fitted probabilities
fitted_vals <- fitted(fit)
#Get Pearson residuals (common for logistic models)
residuals_vals <- residuals(fit, type = "pearson")
#Plot residuals vs fitted values
plot(fitted_vals, residuals_vals,
     xlab = "Fitted Values (Predicted Probabilities)",
     ylab = "Pearson Residuals",
     main = "Residuals vs Fitted Values",
     pch = 19, col = "steelblue")

abline(h = 0, lty = 2, col = "red")  # horizontal line at 0 residual
```

```{r adjusted pseudo maximum likelihood logistic regression}
#Pick the variables we need: outcome, predictors, domain var, and design vars
vars <- c(
  #Outcome
  "IRSUICTHNK",
  #Predictors
  "IRSEX","EDUHIGHCAT","IRPRVHLT","IRHHSIZ2","INCOME","IRALCFY","IRCIGFM",
  "IRNICVAP30N","IRALCBNG30D","SUTINPPY","IRDSTNRV12","IRIMPCONCN","IRMJFY2",
  #Dummy columns (omit reference category dummy!)
  "NEWRACE2_2","NEWRACE2_3","NEWRACE2_4","NEWRACE2_5","NEWRACE2_6","NEWRACE2_7",
  "IRWRKSTAT18_2","IRWRKSTAT18_3","IRWRKSTAT18_4",
  #Domain variable
  "CATAGE",
  #Design variables
  "VEREP","VESTR_C","ANALWT2_C3"
)
#Create a data.frame with just the selected columns
df <- data[, vars]
#Build the survey design
des <- svydesign(
  ids     = ~VEREP,        #PSU / cluster id
  strata  = ~VESTR_C,      #Variance strata
  weights = ~ANALWT2_C3,   #Analysis weight (confirm the exact name)
  data    = df,
  nest    = TRUE
)
#Domain (subpopulation) restriction
des_dom <- subset(des, CATAGE == 2)
#Fit the adjusted PML logistic regression (quasibinomial for robust SEs)
fit <- svyglm(
  IRSUICTHNK ~ IRMJFY2 + IRSEX + EDUHIGHCAT + IRPRVHLT + IRHHSIZ2 + INCOME +
               IRALCFY + IRCIGFM + IRNICVAP30N + IRALCBNG30D + SUTINPPY +
               IRDSTNRV12 + IRIMPCONCN +
               NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
               IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = des_dom,
  family = quasibinomial()
)
#Coefficients â†’ ORs with 95% CIs
co <- coef(fit)
vc <- vcov(fit)
se <- sqrt(diag(vc))
z  <- qnorm(0.975)
#Create dataframe with coefficients
est <- data.frame(
  term = names(co),
  beta = co,
  se   = se,
  OR   = exp(co),
  LCL  = exp(co - z*se),
  UCL  = exp(co + z*se),
  p    = 2*pnorm(-abs(co/se))
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
```

Now we add interactions into our adjusted logistic regression model (one at a time). Since we have less than 30 variables in our model including one main predictor, we will go ahead and test every possible interaction one at a time.

```{r PML adjusted logistic regression with interactions}
#Pick the variables we need: outcome, predictors, domain var, and design vars
vars <- c(
  #Outcome
  "IRSUICTHNK",
  #Predictors
  "IRSEX","EDUHIGHCAT","IRPRVHLT","IRHHSIZ2","INCOME","IRALCFY","IRCIGFM",
  "IRNICVAP30N","IRALCBNG30D","SUTINPPY","IRDSTNRV12","IRIMPCONCN","IRMJFY2","IRCOCFY2","IRHALLUCYFQ2",
  #Dummy columns (omit reference category dummy!)
  "NEWRACE2_2","NEWRACE2_3","NEWRACE2_4","NEWRACE2_5","NEWRACE2_6","NEWRACE2_7",
  "IRWRKSTAT18_2","IRWRKSTAT18_3","IRWRKSTAT18_4",
  #Domain variable
  "CATAGE",
  #Design variables
  "VEREP","VESTR_C","ANALWT2_C3"
)
#Create dataframe with desired columns
df <- data[, vars]
#Build the survey design
des <- svydesign(
  ids     = ~VEREP,        #PSU / cluster id
  strata  = ~VESTR_C,      #Variance strata
  weights = ~ANALWT2_C3,   #Analysis weight (confirm the exact name)
  data    = df,
  nest    = TRUE
)
#Domain (subpopulation) restriction
des_dom <- subset(des, CATAGE == 2)
#Fit the adjusted PML logistic regression (quasibinomial for robust SEs)
fit <- svyglm(
  IRSUICTHNK ~ IRSEX + EDUHIGHCAT + IRPRVHLT +  IRHHSIZ2 + INCOME + IRALCFY + IRCIGFM + IRNICVAP30N + IRALCBNG30D + IRMJFY2 + SUTINPPY +
               IRDSTNRV12 + IRIMPCONCN + 
               NEWRACE2_2 + IRMJFY2 * NEWRACE2_3 + IRMJFY2 * NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
               IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = des_dom,
  family = quasibinomial()
)
#Coefficients â†’ ORs with 95% CIs
co <- coef(fit)
vc <- vcov(fit)
se <- sqrt(diag(vc))
z  <- qnorm(0.975)
#Build dataframe with coefficients
est <- data.frame(
  term = names(co),
  beta = co,
  se   = se,
  OR   = exp(co),
  LCL  = exp(co - z*se),
  UCL  = exp(co + z*se),
  p    = 2*pnorm(-abs(co/se))
)
#Drop the intercept row when reporting
subset(est, term != "(Intercept)")
#Do design-adjusted wald test for interaction (p-value <.05 means the relationship between cannabis use and suicidal ideation significantly differs by the interaction term and coefficient for the interaction term is not equal to 0)
regTermTest(fit, ~ IRMJFY2:NEWRACE2_3)
```

```{r plot residuals vs fitted values for adjusted PML model}
res_dev <- residuals(fit, type = "deviance")
plot(fitted(fit), res_dev, xlab="Fitted (p-hat)", ylab="Deviance residuals",
     main="Residuals vs Fitted (Deviance)", pch=19, col="steelblue")
abline(h=0, lty=2, col="red")
```

```{r non-linear test, warning=FALSE, message=FALSE}
#Required libraries: rms & survey
library(survey)
library(rms)
#Pick the variables we need: outcome, predictors, domain var, and design vars
vars <- c(
  #Outcome
  "IRSUICTHNK",
  #Predictors
  "IRSEX","EDUHIGHCAT","IRPRVHLT","IRHHSIZ2","INCOME","IRALCFY","IRCIGFM",
  "IRNICVAP30N","IRALCBNG30D","SUTINPPY","IRDSTNRV12","IRIMPCONCN","IRMJFY",
  #Dummy columns (omit reference category dummy!)
  "NEWRACE2_2","NEWRACE2_3","NEWRACE2_4","NEWRACE2_5","NEWRACE2_6","NEWRACE2_7",
  "IRWRKSTAT18_2","IRWRKSTAT18_3","IRWRKSTAT18_4",
  #Domain variable
  "CATAGE",
  #Design variables
  "VEREP","VESTR_C","ANALWT2_C3"
)
#Create a data.frame with just the selected columns
df <- data[, vars]
#Build the survey design
des <- svydesign(
  ids     = ~VEREP,        #PSU / cluster id
  strata  = ~VESTR_C,      #Variance strata
  weights = ~ANALWT2_C3,   #Analysis weight (confirm the exact name)
  data    = df,
  nest    = TRUE
)
#Domain (subpopulation) restriction
des_dom <- subset(des, CATAGE == 2)
#Fit linear model
fit_linear <- svyglm(
  IRSUICTHNK ~ IRMJFY + IRSEX + EDUHIGHCAT + IRPRVHLT + IRHHSIZ2 + INCOME +
    IRALCFY + IRCIGFM + IRNICVAP30N + IRALCBNG30D + SUTINPPY +
    IRDSTNRV12 + IRIMPCONCN +
    NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
    IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = des_dom,
  family = quasibinomial()
)
#Fit non-linear model
fit_rcs <- svyglm(
  IRSUICTHNK ~ rcs(IRMJFY) + IRSEX + EDUHIGHCAT + IRPRVHLT + IRHHSIZ2 + INCOME +
    IRALCFY + IRCIGFM + IRNICVAP30N + IRALCBNG30D + SUTINPPY +
    IRDSTNRV12 + IRIMPCONCN +
    NEWRACE2_2 + NEWRACE2_3 + NEWRACE2_4 + NEWRACE2_5 + NEWRACE2_6 + NEWRACE2_7 +
    IRWRKSTAT18_2 + IRWRKSTAT18_3 + IRWRKSTAT18_4,
  design = des_dom,
  family = quasibinomial()
)
#Test the null hypothesis: nonlinear spline components = 0
regTermTest(fit_rcs, ~ rcs(IRMJFY))
```

```{r plot residuals vs fitted values for RCS adjusted PML model}
res_dev <- residuals(fit_rcs, type = "deviance")
plot(fitted(fit_rcs), res_dev, xlab="Fitted (p-hat)", ylab="Deviance residuals",
     main="Residuals vs Fitted (Deviance)", pch=19, col="steelblue")
abline(h=0, lty=2, col="red")
```
